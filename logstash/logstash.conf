input {
  file {
    path => "/opt/data/junit.xml"
    start_position => "beginning"
    sincedb_path => "/dev/null" # For testing, Logstash re-reads the file on each start
    # Use a multiline codec to group lines belonging to a single <testcase> element
    codec => multiline {
      pattern => "^<testcase\b" # Pattern indicating the start of a new testcase event
      negate => true
      what => "previous"       # Append lines not matching the pattern to the previous line
      auto_flush_interval => 1 # Ensure the last event is flushed even if no new line matches
    }
  }
}
filter {
  # Add filters to parse the JUnit XML file
  xml {
    source => "message"
    store_xml => false # Don't store the full XML tree in the event
    xpath => [
      # Extract fields from the <testcase> element
      "//testcase[failure]/@name", "testcase_name",
      "//testcase/@time", "testcase_time",
      "//testcase/failure/text()", "failure_message",    # Text content of the <failure> tag
      "//testcase/failure", "failure_content",            # Text content of the <failure> tag
      "//testcase/system-out", "system_out_content"      # Text content of the <system-out> tag
    ]
    # remove_field => ["message"] # Optional: uncomment to remove the original XML message field after parsing
  }

  # Drop the event if the failure_message field was not populated (i.e., no failure text was found)
  if ![failure_message] {
    drop { }
  }
}
output {
  stdout { codec => rubydebug }
  elasticsearch {
    hosts => ["https://192.168.1.140:30020"]
    index => "junit_results"
    ssl_certificate_verification => false
    user => "elastic"
    # oc get secret quickstart-es-elastic-user -n default -o jsonpath='{.data.elastic}' | base64 --decode; echo
    password => "8Na7TT6d9uVR2NP724QU4Oa5"
    
  }
}
